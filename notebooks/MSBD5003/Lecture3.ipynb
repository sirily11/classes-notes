{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lecture3.ipynb","provenance":[],"authorship_tag":"ABX9TyPAnZJ3PQeZySXmhUZ8rKeT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"P1adJw_OsJrK","executionInfo":{"status":"ok","timestamp":1600776369263,"user_tz":-480,"elapsed":38807,"user":{"displayName":"Qiwei Li","photoUrl":"","userId":"09519962397524608991"}},"outputId":"5081c4a3-623f-400f-b8e5-7d9e73616476","colab":{"base_uri":"https://localhost:8080/","height":238}},"source":["!pip install pyspark"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/26/198fc8c0b98580f617cb03cb298c6056587b8f0447e20fa40c5b634ced77/pyspark-3.0.1.tar.gz (204.2MB)\n","\u001b[K     |████████████████████████████████| 204.2MB 69kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 40.7MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612243 sha256=afa56cc6a9466c8bd467ecaf305826a28ca15fb5f31ee4f848525e71d4193f60\n","  Stored in directory: /root/.cache/pip/wheels/5e/bd/07/031766ca628adec8435bb40f0bd83bb676ce65ff4007f8e73f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.0.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3Er-QTaNsZne"},"source":["## Example: Linear-time selection"]},{"cell_type":"markdown","metadata":{"id":"A6BeZkfGsTSx"},"source":["### Problem:\n","— Input: an array A of n numbers (unordered), and k\n","\n","— Output: the k-th smallest number (counting from 0)\n","\n","### Algorithm\n","1. $x=A[0]$\n","partition A into\n","$A[0..mid-1] < A[mid] = x < A[mid+1..n-1]$\n","3. if $mid =k$ then return $x$\n","\n","4. if $k<mid$ then $A= A[O..mid-1]$\n","if k > mid then $A = A[mid+1,n-1], k= k— mid-1$\n","5. gotostep 1"]},{"cell_type":"markdown","metadata":{"id":"nYG8nhUiv50G"},"source":["### Key-value Pairs\n","\n","While most Spark operations work on RDDs containing any type of objects, a few special operations are only available on RDDs of key-value pairs. \n","In Python, these operations work on RDDs containing built-in Python tuples such as (1, 2). Simply create such tuples and then call your desired operation.\n","For example, the following code uses the reduceByKey operation on key-value pairs to count how many times each line of text occurs in a file:\n","\n","```python\n","lines = sc.textFile(\"README.md\")\n","pairs = lines.map(lambda s: (s, 1))\n","counts = pairs.reduceByKey(lambda a, b: a + b)\n","```\n","\n","We could also use ```counts.sortByKey()```, for example, to sort the pairs alphabetically, and finally counts.collect() to bring them back to the driver program as a list of objects."]},{"cell_type":"code","metadata":{"id":"lMkmbyu_tAh9"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rIH86a0n980o"},"source":["### PMI\n","\n","PMI (pointwise mutual information) is a measure of association used in information theory and statistics.\n","\n","Given a list of pairs (x, y)\n","\n","$$pmi(x, y) = log\\frac{p(x,y)}{p(x)p(y}$$\n","\n","where \n","- $p(x)$: probability of x\n","- $p(y)$: probability of y\n","-$p(x,y)$: joint probability\n","\n","Example: \n","p(x=0) = 0.8, p(x=1)=0.2, p(y=0)=0.25, p(y=1)=0.75\n","\n","- pmi(x=0;y=0)\t=\t−1\n","- pmi(x=0;y=1)\t=\t0.222392\n","- pmi(x=1;y=0)\t=\t1.584963\n","- pmi(x=1;y=1)\t=\t-1.584963\n","\n","\n","Example notebook see: note book in class/PMI"]},{"cell_type":"code","metadata":{"id":"9KO5qNssaKyS"},"source":[""],"execution_count":null,"outputs":[]}]}