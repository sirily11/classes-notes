{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lecture7.ipynb","provenance":[],"authorship_tag":"ABX9TyNM/JbfBeSSofQgowkLBRyN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"QNkB4iZs9J7u"},"source":["Code at internal.ipynb"]},{"cell_type":"markdown","metadata":{"id":"jVGYhPeV9TqS"},"source":["## Data Partitioning"]},{"cell_type":"markdown","metadata":{"id":"ZNkbm4jj9XLR"},"source":["- RDDs are stored in partitions. When performing computations on RDDs, these partitions can be operated on in parallel. \n","\n","- You get better parallelism when the partitions are balanced.\n","\n","- When RDDs are first created, the partitions are balanced.\n","However, partitions may get out of balance after certain transformations."]},{"cell_type":"markdown","metadata":{"id":"VdUKWm6A_pja"},"source":["### Hash Partitioning\n","\n","We can view the contents of each partition:\n","- e.g., prime.glom().collect()[1][0:4]\n","- We see that it hashed all numbers x such that x mod 8 = 1 to partition #1\n","\n","In general, hash partitioning allocates tuple (k, v) to partition p where \n","- p = k.hashCode() % numPartitions\n","\n","Usually works well but be aware of bad inputs!"]},{"cell_type":"markdown","metadata":{"id":"WnqplDhOAF2n"},"source":["### Shuffle\n","\n","Spark uses shuffles to implement wide dependencies\n","- Examples: reduceByKey, repartition, coalesce, join (on RDDs not partitioned using the same partitioner)\n","\n","Spark generates sets of tasks - map tasks to organize the data, and a set of reduce tasks to group/aggregate it.\n","\n","Internally, Spark builds a hash table within each task to perform the grouping.\n","\n","If the hash table is too large, Spark will spill these tables to disk, incurring the additional overhead of disk I/O\n","\n","RDDs resulting from shuffles are automatically cached."]},{"cell_type":"markdown","metadata":{"id":"95r3b3oTLkYD"},"source":["### Range partitioning\n","\n","For data types that have or ordering defined\n","- Examples: Int, Char, String, …\n","- Internally, Spark samples the data so as to produce more balanced partitions.\n","- Used by default after sorting\n","Example: \n","- An RDD with keys [8, 96, 240, 400, 401, 800], \n","- Number of partitions: 4\n","- In this case, hash partitioning distributes the keys as follows among the partitions:\n","- partition 0: [8, 96, 240, 400, 800]\n","- partition 1: [401]\n","- partition 2: []\n","- partition 3: []\n","\n","Range partitioning would improve the partitioning significantly"]},{"cell_type":"markdown","metadata":{"id":"d8CPzEr6L2XO"},"source":["## Partitioner inheritance\n","\n","Operations on Pair RDDs that hold to (and propagate) a partitioner:\n","\n","- mapValues (if parent has a partitioner)\n","- flatMapValues (if parent has a partitioner)\n","- filter (if parent has a partitioner)"]},{"cell_type":"code","metadata":{"id":"C6KyC9U-yvgs"},"source":[""],"execution_count":null,"outputs":[]}]}